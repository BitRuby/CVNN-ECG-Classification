{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "865721f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer, Dropout\n",
    "from tensorflow import convert_to_tensor, float32\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from scipy import signal\n",
    "import pywt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bda17658",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Dataset/mitbih_database\"\n",
    "filenames = next(os.walk(path))[2]\n",
    "records=list()\n",
    "annotations=list()\n",
    "filenames.sort()\n",
    "for f in filenames:\n",
    "    filename, file_extension = os.path.splitext(f)\n",
    "    if(file_extension=='.csv'):\n",
    "        records.append(path+'/'+filename+file_extension)\n",
    "    else:\n",
    "        annotations.append(path+'/'+filename+file_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0c4f976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_record_signals(index):\n",
    "    signals = []\n",
    "    labels = []\n",
    "    with open(records[index],'r') as csvfile:\n",
    "        filereader = csv.reader(csvfile,delimiter=',',quotechar='|')\n",
    "        row_index = -1\n",
    "        for row in filereader:\n",
    "            if(row_index >= 0):\n",
    "                signals.insert(row_index, int(row[1]))\n",
    "            row_index += 1\n",
    "        signals = np.array(signals)\n",
    "    with open(annotations[index],'r') as csvfile:\n",
    "        filereader = csv.reader(csvfile,delimiter=',',quotechar='|')\n",
    "        row_index = -1\n",
    "        for row in filereader:\n",
    "            if(row_index >= 0):\n",
    "                elements = list(filter(lambda x: len(x) > 0, row[0].split(\" \")))\n",
    "                labels.insert(row_index, [int(elements[1]), elements[2]])\n",
    "            row_index += 1\n",
    "        labels = np.array(labels)\n",
    "    return signals, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d684af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_detrend_and_butterworth(signals):\n",
    "    fs = 360.0\n",
    "    N = 650000\n",
    "    T = N / fs\n",
    "    t = np.linspace(0, T, N, endpoint=False)\n",
    "\n",
    "    # Detrend (usuniecie DC/linearna skÅ‚adowa)\n",
    "    data_detrended = signal.detrend(signals)\n",
    "\n",
    "    # Butterworth bandpass (np. 0.5 - 40 Hz)\n",
    "    lowcut = 0.5\n",
    "    highcut = 40.0\n",
    "    nyq = 0.5 * fs\n",
    "    b, a = signal.butter(4, [lowcut/nyq, highcut/nyq], btype='band')\n",
    "    data_filt = signal.filtfilt(b, a, data_detrended)  # zero-phase\n",
    "    return data_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "060da5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wavelet_features(data):\n",
    "    coeffs = pywt.wavedec(data, 'sym4', level=4)\n",
    "\n",
    "    features = []\n",
    "    for c in coeffs[1:]:\n",
    "        features.append(np.sum(c**2))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a7232360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_wavelet(data): \n",
    "    w = pywt.Wavelet('sym4')\n",
    "    maxlev = pywt.dwt_max_level(len(data), w.dec_len)\n",
    "    threshold = 0.04 # Threshold for filtering\n",
    "\n",
    "    coeffs = pywt.wavedec(data, 'sym4', level=maxlev)\n",
    "    for i in range(1, len(coeffs)):\n",
    "        coeffs[i] = pywt.threshold(coeffs[i], threshold*max(coeffs[i]))\n",
    "        \n",
    "    datarec = pywt.waverec(coeffs, 'sym4')\n",
    "    return datarec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "66fb5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_welch(data):\n",
    "    fs = 360.0\n",
    "    nperseg = 64\n",
    "    noverlap = nperseg // 2\n",
    "    f_welch, Pxx = signal.welch(data, fs=fs, nperseg=nperseg, noverlap=noverlap, window='hann')\n",
    "    return f_welch, Pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c3e0b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fft(data):\n",
    "    fs = 360.0\n",
    "    N = len(data)\n",
    "    X = np.fft.fft(data)\n",
    "    freqs = np.fft.fftfreq(N, 1/fs)\n",
    "    positive = freqs >= 0\n",
    "    freqs_pos = freqs[positive]\n",
    "    X_pos = np.abs(X[positive]) / N\n",
    "    return X_pos, freqs_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3d2f9efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 650000\n",
      "Value Range: 611 -> 1538\n",
      "Classes: ['+' 'N' 'V' '~']\n"
     ]
    }
   ],
   "source": [
    "signals, labels = get_record_signals(6)\n",
    "print(\"Number of samples:\", len(signals))\n",
    "print(\"Value Range:\", np.min(signals), \"->\", np.max(signals))\n",
    "print(\"Classes:\", np.unique(labels[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6f2fd85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['83', '~'], dtype='<U11')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "879b7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(window_size):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    half_w = window_size // 2\n",
    "    valid_labels = {'A', 'L', 'N', 'R', 'V'}\n",
    "\n",
    "    for i in range(len(records)):\n",
    "        signals, labels = get_record_signals(i)\n",
    "        signals = apply_detrend_and_butterworth(signals)\n",
    "        sig_len = len(signals)\n",
    "\n",
    "        mask = np.isin(labels[:, 1], list(valid_labels))\n",
    "        filtered_labels = labels[mask]\n",
    "        \n",
    "        for j in range(3, len(filtered_labels) - 1):\n",
    "            # prev_2_label_pos = int(filtered_labels[j - 2][0])\n",
    "            # prev_1_label_pos = int(filtered_labels[j - 1][0])\n",
    "            # label_pos = int(filtered_labels[j][0])\n",
    "            # next_1_label_pos = int(filtered_labels[j + 1][0])\n",
    "            prev_3_label_pos = int(filtered_labels[j - 3][0])\n",
    "            prev_2_label_pos = int(filtered_labels[j - 2][0])\n",
    "            prev_1_label_pos = int(filtered_labels[j - 1][0])\n",
    "            label_pos = int(filtered_labels[j][0])\n",
    "            next_1_label_pos = int(filtered_labels[j + 1][0])\n",
    "            \n",
    "            RR_j_2 = prev_2_label_pos - prev_3_label_pos\n",
    "            start_prev_2 = int(int(filtered_labels[j-2][0]) - 0.6 * RR_j_2)\n",
    "            end_prev_2  = int(int(filtered_labels[j-2][0]) + 0.8 * RR_j_2)\n",
    "\n",
    "            RR_j_1 = prev_1_label_pos - prev_2_label_pos\n",
    "            start_prev_1 = int(int(filtered_labels[j-1][0]) - 0.6 * RR_j_1)\n",
    "            end_prev_1  = int(int(filtered_labels[j-1][0]) + 0.8 * RR_j_1)\n",
    "            \n",
    "            RR_j = label_pos - prev_1_label_pos\n",
    "            start_curr = int(int(filtered_labels[j][0]) - 0.6 * RR_j)\n",
    "            end_curr  = int(int(filtered_labels[j][0]) + 0.8 * RR_j)\n",
    "            \n",
    "            RR_j_p1 = next_1_label_pos - label_pos\n",
    "            start_next_1 = int(int(filtered_labels[j+1][0]) - 0.6 * RR_j_p1)\n",
    "            end_next_1  = int(int(filtered_labels[j+1][0]) + 0.8 * RR_j_p1)\n",
    "\n",
    "\n",
    "            # signal_min_2 = signals[prev_2_label_pos - half_w:prev_2_label_pos + half_w]\n",
    "            # signal_min_1 = signals[prev_1_label_pos - half_w:prev_1_label_pos + half_w]\n",
    "            # signal_current = signals[label_pos - half_w:label_pos + half_w]\n",
    "            # signal_next_1 = signals[next_1_label_pos - half_w:next_1_label_pos + half_w]\n",
    "\n",
    "\n",
    "            if start_prev_2 < 0 or end_next_1 > sig_len:\n",
    "                continue\n",
    "\n",
    "            # wavelet_energy = apply_wavelet(signals[start:end])\n",
    "            # wavelet_prev_1 = apply_wavelet(signal_min_1)\n",
    "            # wavelet_curr = apply_wavelet(signal_current)\n",
    "            # wavelet_next_1 = apply_wavelet(signal_next_1)\n",
    "            # fusion = [*wavelet_prev_1, *wavelet_curr, *wavelet_next_1]\n",
    "            X.append([\n",
    "                *apply_wavelet(signal.resample(signals[start_prev_1:end_prev_1], 256)),\n",
    "                *apply_wavelet(signal.resample(signals[start_curr:end_curr], 256)),\n",
    "                *apply_wavelet(signal.resample(signals[start_next_1:end_next_1], 256))])\n",
    "            y.append(filtered_labels[j][1])\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ecb2292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "WINDOW_SIZE = 250\n",
    "EPOCHS = 500\n",
    "BATCH_SIZE = 128\n",
    "TEST_SIZE = 0.25\n",
    "N_RUNS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c497c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signals_list = [X[y.index(\"A\")], X[y.index(\"L\")], X[y.index(\"N\")], X[y.index(\"R\")], X[y.index(\"V\")]]\n",
    "# titles = [\"A - Atrial premature beat (APB)\", \"L - Left bundle branch block beat (LBBB)\", \"N - Normal beat\", \"R - Right bundle branch block beat (RBBB)\", \"V - Premature ventricular contraction (PVC)\"]\n",
    "\n",
    "# fig, ax = plt.subplots(1, 5, figsize=(20, 5))\n",
    "\n",
    "# for a, sig, title in zip(ax, signals_list, titles):\n",
    "#     a.plot(range(0, len(sig)), sig)\n",
    "#     a.set_title(title)\n",
    "#     a.set_xlabel(\"Sample\")\n",
    "#     a.grid(True)\n",
    "\n",
    "# ax[0].set_ylabel(\"Amplitude\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f0bf8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run() # Ensure any previous runs are closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b6c6ac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/28 15:25:11 INFO mlflow.tracking.fluent: Experiment with name 'DNN_MIT_BIH_Arrythmia_Classification_With_Detrend_and_Butterworth_and_Relative_Window_Wavelet_And_Neighboring_Windows' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780/780 [==============================] - 1s 2ms/step\n",
      "780/780 [==============================] - 2s 2ms/step\n",
      "780/780 [==============================] - 1s 2ms/step\n",
      "780/780 [==============================] - 2s 3ms/step\n",
      "780/780 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "for i in range(N_RUNS):\n",
    "    X, y = process_data(window_size=WINDOW_SIZE)\n",
    "    \n",
    "    # values, counts = np.unique(y, return_counts=True)\n",
    "    # plt.bar(values, counts)\n",
    "    # plt.title('Class Distribution')\n",
    "    # plt.xlabel('Class')\n",
    "    # plt.ylabel('Number of Samples')\n",
    "    # plt.show()\n",
    "    \n",
    "    mlflow.start_run()\n",
    "    mlflow.set_experiment(\"DNN_MIT_BIH_Arrythmia_Classification_With_Detrend_and_Butterworth_and_Relative_Window_Wavelet_And_Neighboring_Windows\")\n",
    "    mlflow.log_param(\"model\", \"DNN-Dense-128-Dense-128-Softmax\")\n",
    "    mlflow.log_param(\"input_dim\", 768)\n",
    "    mlflow.log_param(\"epochs\", EPOCHS)\n",
    "    mlflow.log_param(\"batch_size\", BATCH_SIZE)\n",
    "    mlflow.log_param(\"optimizer\", \"adam\")\n",
    "    mlflow.log_param(\"loss\", \"categorical_crossentropy\")\n",
    "    mlflow.log_param(\"test_size\", TEST_SIZE)\n",
    "    mlflow.log_param(\"scaler\", \"MinMaxScaler\")\n",
    "    mlflow.log_param(\"classes\", \"A,L,N,R,V\")\n",
    "    mlflow.log_param(\"window_size\", WINDOW_SIZE)\n",
    "    # Train/test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=42)\n",
    "    \n",
    "    #Label Binarization\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    y_train = lb.fit_transform(y_train)\n",
    "    y_test = lb.transform(y_test)\n",
    "    \n",
    "    # Under-sampling\n",
    "    rus = RandomUnderSampler(sampling_strategy='auto')\n",
    "    X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
    "    \n",
    "    #Min/Max Scaling\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_res = scaler.fit_transform(X_train_res)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    # print(f\"Using device: {device}\")\n",
    "    # print(type(X_test))\n",
    "    # print(X_test.dtype)\n",
    "    # print(X_test.shape)\n",
    "    # print(type(X_test[0]))\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(768,), name=\"InputLayer\"))\n",
    "    model.add(Dense(units=128, activation=\"relu\", name=f\"HiddenLayer-1\"))\n",
    "    model.add(Dense(units=128, activation=\"relu\", name=f\"HiddenLayer-2\"))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'],\n",
    "                    )\n",
    "    history = model.fit(X_train_res, y_train_res,\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE, verbose=0)\n",
    "        \n",
    "    X_test_tf = convert_to_tensor(X_test, dtype=float32)\n",
    "    y_test_tf = convert_to_tensor(y_test)\n",
    "\n",
    "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None\n",
    "    )\n",
    "\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"macro\"\n",
    "    )\n",
    "\n",
    "    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"weighted\"\n",
    "    )\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    mlflow.log_metric(\"precision_macro\", precision_macro)\n",
    "    mlflow.log_metric(\"recall_macro\", recall_macro)\n",
    "    mlflow.log_metric(\"f1_macro\", f1_macro)\n",
    "\n",
    "    mlflow.log_metric(\"precision_weighted\", precision_weighted)\n",
    "    mlflow.log_metric(\"recall_weighted\", recall_weighted)\n",
    "    mlflow.log_metric(\"f1_weighted\", f1_weighted)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_norm = cm / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.heatmap(\n",
    "        cm_norm,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap=\"Blues\"\n",
    "    )\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"confusion_matrix.png\")\n",
    "    plt.close()\n",
    "\n",
    "    mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    with open(\"classification_report.txt\", \"w\") as f:\n",
    "        f.write(report)\n",
    "    mlflow.log_artifact(\"classification_report.txt\")\n",
    "    mlflow.end_run()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "be3f5441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  params.window_size params.epochs                     params.model  \\\n",
      "0                250           500  DNN-Dense-128-Dense-128-Softmax   \n",
      "\n",
      "   accuracy_mean  accuracy_std  f1_macro_mean  f1_macro_std  \n",
      "0       0.960594      0.005351       0.908943      0.008652  \n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"DNN_MIT_BIH_Arrythmia_Classification_With_Detrend_and_Butterworth_and_Relative_Window_Wavelet_And_Neighboring_Windows\"\n",
    "\n",
    "runs = mlflow.search_runs(\n",
    "    experiment_names=[experiment_name],\n",
    "    output_format=\"pandas\"\n",
    ")\n",
    "\n",
    "summary = (\n",
    "    runs\n",
    "    .groupby([\"params.window_size\", \"params.epochs\", \"params.model\"])\n",
    "    .agg(\n",
    "        accuracy_mean=(\"metrics.accuracy\", \"mean\"),\n",
    "        accuracy_std=(\"metrics.accuracy\", \"std\"),\n",
    "        f1_macro_mean=(\"metrics.f1_macro\", \"mean\"),\n",
    "        f1_macro_std=(\"metrics.f1_macro\", \"std\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
